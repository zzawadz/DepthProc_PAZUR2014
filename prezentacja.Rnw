\documentclass{beamer}
\usetheme{Warsaw}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{lmodern}
\usepackage{polski}
\usepackage{graphicx} 
\usepackage{color}
\usepackage{attrib}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\begin{document}

\newcommand{\RR}{\ensuremath{\mathbb{R}^d}}

\author[D. Kosiorowski, Z. Zawadzki] % (optional, for multiple authors)
{
\textbf{Daniel Kosiorowski}\inst{1}, \textbf{Zygmunt Zawadzki}\inst{2}}
\institute[CUE] % (optional)
{
\inst{1} Uniwersytet Ekonomiczny w Krakowie, Katedra Statystyki \and
\inst{2} Uniwersytet Ekonomiczny w Krakowie, student Analityki Gospodarczej
}

\title{Odporna eksploracja danych z wykorzystaniem pakietu DepthProc}

\begin{frame}
  \titlepage
  
<<echo=FALSE,warning=FALSE,message=FALSE>>=
library(xts)
library(knitr)
library(grid)
library(robust)
library(dplyr)
library(reshape2)
library(magrittr)
library(DepthProc)
library(RColorBrewer)
library(hdrcde)

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(cex = 1.5, lwd = 2, mar = c(4,4,3,1))  # smaller margin on top and right
})

opts_chunk$set(small.mar = TRUE, fig.width = 6.5, fig.height = 3,fig.pos='center',  message = FALSE, size='footnotesize', echo = FALSE, cache=TRUE)

# Borrowed from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


# borrowed from https://github.com/hadley/bigvis/blob/master/R/challenge.r
rchallenge <- function(n) {
  nt <- rbinom(1, n, 1 / 3)
  ngamma <- n - nt

  spike <- 2 * rt(nt, df = 2) + 15
  spike[spike < 0] <- 0

  slope <- rgamma(ngamma, 2, 1/3)

  c(spike, slope)
}


@
  
  
\end{frame}

\section{Statystyka odporna}

\begin{frame}
  \frametitle{Statystyka odporna}
  
Procedury statystyczne konstruuje się przy założeniu, że spełniane są określone warunki dotyczące mechanizmu generującego dane (np. dane generowane są przez rozkład normalny, i są niezależne od siebie).

W praktyce, możemy mieć do czynienia z odstępstwem od przyjmowanych założeń. Przykładowo w danych mogą występować obserwacje odstające, znacząco odbiegające od reszty danych. W takiej systuacji jakość procedury statystycznej może znacząco się obniżyć (utrata efektywności estymatora, wzrost obciążenia, itp).

Celem statystyki odpornej jest zaproponowanie procedur dających wiarygodne oszacowania również w  przypadku gdy rozkład generujący dane odbiega od zakładanego rozkładu.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Statystyka odporna}
\Large
"\emph{Robustness theories can be viewed as stability theories of statistical inference. Robust statistics deals with stability, relative to model perturbation. \textbf{Hampel et all (1986)}}"

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}
  \frametitle{Statystyka odporna - przykład - korelacja}
  
Dane jest dwadzieścia obserwacji z dwuwymiarowego rozkładu normalnego ze współczynnikiem korelacji 0.8. Dwie obserwacje zastąpiono obserwacjami odstającymi. Zmiana jedynie 10\% oberwacji spowodowała drastyczną różnicę we wskazaniach klasycznego estymatora, natomiast w przypadku metody odpornej, wpływ obserwacji odstających został mocno ograniczony.

<<echo=FALSE>>=
set.seed(123)
cov = cbind(c(1,0.8),c(0.8,1))
x = mvrnorm(20, c(0,0), cov)


corRFnc = function(x)
{
  covMcd(x) %>% "$"(cov) %>% 
    cov2cor %>%
    "["(2,1) %>% round(2)
}

xp = 0.6
par(mfrow = c(1,2), mar = c(2,2,2,1))
plot(x, pch = 19, col = "red", xlab = "", ylab = "")
text(xp,-1.2, paste("Korelacja: ", round(cor(x)[2,1],2)))
text(xp,-1.6, paste("Korelacja odporna: ", corRFnc(x)))

x2 = x[order(x[,2]),]
x2[1,2] = -x2[1,2]
x2[20,2] = -x2[20,2]
plot(x2, pch = 19, col = "blue", xlab = "", ylab = "")
text(xp,-1.2, paste("Korelacja: ", round(cor(x2)[2,1],2)))
text(xp,-1.6, paste("Korelacja odporna: ", corRFnc(x2)))
@
\end{frame}


\begin{frame}
\frametitle{Statystyka odporna - Punkt Załamania}
\small
Niech ${{{X}}^{n}}$ będzie próbą o rozmiarze $n$. \textbf{Punkt załamania próby skończonej} (BP - ang. breakdown point) estymatora $T$ zdefiniowany jest jako:
$$BP(T,{{X}^{n}})=\left\{ \frac{m}{n}:\left\| T(X_{m}^{n})-T({{X}^{n}}) \right\|>\delta  \right\},$$
 gdzie $X_{m}^{n}$ jest zanieczyszczoną próbą powstałą przez zastąpienie punktów z ${{ {X}}^{n}}$ dowolnymi wartościami, $\left\| \cdot  \right\|$ określa normę, $\delta $ to określony próg.

\begin{center}
\normalsize
PUNKT ZAŁAMANIA PRÓBY SKONCZONEJ ESTYMATORA – najmniejsza 
frakcja złych obserwacji w próbie, która sprawia, że estymator staje się bezużyteczny –
np. jego obciążenie staje się zbyt wysokie.
\vspace{20pt}


\begin{block}{Przykładowe BP}
\centering
BP dla odchylenia standardowego wynosi $\frac{1}{n} \approx 0$

BP dla mediany wynosi $\approx 50\%$
\end{block}


\end{center}

Więcej na temat badania odporności procedury statystycznej można znaleźć w \cite{DK2012}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}
\frametitle{Eksploracyjna analiza danych}

Techniki \textbf{Eksploracyjnej Analizy Danych} (EAD) pozwalają lepiej zrozumieć dane z którymi ma się do czynienia. Stosunkowo proste wykresy jak histogram czy boxplot pozwalają w przybliżony sposób określić rozkład danych, lub sprawdzić czy występują obserwacje odstające\cite{Tukey1980}. 

Wiele użytecznych i prostych w interpretacji technik EAD jest ograniczona jedynie do danych jednowymiarowych (histogram, boxplot, wykres kwantyl-kwantyl), bądź dwuwymiarowych (heatmapy). Z praktycznego punktu widzenia wartościowe byłoby uogólnienie ich na większą liczbę wymiarów, zachowując jednocześnie prostotę interpretacji.


\end{frame}


\begin{frame}
  \frametitle{Wykres kwantyl-kawntyl}
\small
Bardzo użyteczną techniką EAD jest wykres kwantyl-kwantyl, pozwalający w graficzny sposób sprawdzić, czy dane mogą być generowane przez zakaładny rozkład, lub czy dwie próby pochodzą z tego samego rozkładu.

<<fig.height = 2>>=
set.seed(123)
x = rnorm(200)
y = rt(200, df = 3)
yt2 = rt(200, df = 3)
par(mfrow = c(1,2), mar = c(4,4,1,1))
qqplot(x,y, xlab = "Normal", ylab = "t(5)")
qqplot(y,yt2, xlab = "t(5)", ylab = "t(5)")
@

Posiada on jednak tę kluczową wadę, że do jego konstrukcji wymagany jest kwantyl - przez co trudno uogólnić taki wykres na przypadek wielowymiarowy. Definicja kwantyla opiera się na porządku liniowym liczb rzeczywistych w jednym wymierze. W wielu wymiarach nie ma prostej definicji takiego porządku, przez co zastosowanie tego typu wykresu do danych wielowymiarowych jest niemożliwe.

\end{frame}

\begin{frame}
  \frametitle{Koncepcja głębi danych}
  
Statystyczna funkcja głębi ma na celu kompensacje braku porządku liniowego w $\RR, d \leq 2$. Zakładając pewien rozkład prawdopodobieństwa $F$ na $\RR$, funkcja głębi $D(x,F)$ umożliwia porządkowanie punktów na zasadzie odstawania od centrum rozkładu. 

W przypadku próby $X^n = \{x_1,...,x_n\}$ rozkład F zastępowany jest rozkładem $F_n$ wyznaczonym na podstawie $X^n$.

Formalną definicję funkcji głębi można znaleźć w \cite{Liu:1999} i \cite{Zuo:2000}.

\end{frame}

\begin{frame}
  \frametitle{Najprostszy przykład - głebia Euklidesa}

\begin{columns}[T] % align columns
\begin{column}{.55\textwidth}

Głębia Euklidesa:
\begin{equation}
D_E(x, X^n) = \frac{1}{1+||x - \bar{x}||},
\end{equation}

gdzie $\bar{x}$ to wektor średnich z próby $X^n$.\\ 
\vspace{30pt}
Zaletą tej głębi jest jedynie szybkość obliczeń. Jednak w praktycznych przypadkach głębia Euklidesa nie ma zastosowania - nie radzi sobie z eliptycznym kształtem danych, lub skośnymi danymi.

\end{column}%
\hfill%
\begin{column}{.48\textwidth}

  \begin{figure}
    \centering
    \vspace{-30pt}
    \includegraphics[width=1\textwidth]{contours/e1}
  \end{figure}
  \begin{figure}
    \vspace{-60pt}
    \centering
    \includegraphics[width=1\textwidth]{contours/e2}
  \end{figure}

\end{column}%
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{Głębia Mahalanobisa}
\small
\begin{columns}[T] % align columns
\begin{column}{.55\textwidth}

Głębia Mahalanobisa zdefiniowana jest jako:
\begin{equation}
D_E(x, X^n) = \frac{1}{1+(x-\bar{x})^T\Sigma (x-\bar{x})},
\end{equation}

gdzie $\bar{x}$ to wektor średnich z próby $X^n$.\\ 
\vspace{5pt}
Głębia Mahalanobisa podobnie jak głębia Euklidesa opiera się na odległości. W tym przypadku by otrzymać wiarygodne wartości, należałoby zastosowac odporny estmator macierzy kowariancji, jak również odporną miarę położenia. W takim przypadku ciężko zdefiniować nową miarę położenia opartą na funkcji głębi.

\end{column}%
\hfill%
\begin{column}{.48\textwidth}

  \begin{figure}
    \centering
    \vspace{-30pt}
    \includegraphics[width=1\textwidth]{contours/m1}
  \end{figure}
  \begin{figure}
    \vspace{-60pt}
    \centering
    \includegraphics[width=1\textwidth]{contours/m2}
  \end{figure}

\end{column}%
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{Głębia Tukey'a}

Funkcją głębi przyporządkowująca punktowi $x$ najmniejsze prawdopodobieństwo zgromadzone na domkniętej półprzestrzeni, do której brzegu należy ten punkt, nazywamy głębią domkniętej półprzestrzeni Tukeya.

\begin{columns}[T] % align columns
\begin{column}{.45\textwidth}
\vspace{-20pt}
<<fig.height=2.5, fig.width=2.5, dev.args=list(pointsize = 5)>>=
set.seed(123)

x = mvrnorm(10, c(0,0), diag(2))
dp = depthTukey(x, exact = TRUE)
plot(x, col = dp *10, pch = 19, xlab = "", ylab = "")

par(mar = c(1,1,1,1))
i = 7
a = +0.5
abline(b = (x[i,2]-a)/x[i,1],a = a, col = "blue")

@

\end{column}%
\hfill%
  \begin{column}{.55\textwidth}
  
  Ta funckja głębi nie opiera się na infrmacji metrycznej, dotyczącej odległości pomiędzy punktami, tylko na ich wzajemnym położeniu. Dlatego też głębia punktu leżącego z dala od chmury punktów, będzie taka sama jak punktu leżącego na jej skraju. 
  
  \end{column}%
\end{columns}

\end{frame}


\begin{frame}
[fragile]\frametitle{Głębia Tukey'a. cd - wywołanie funkcji}

<<eval=FALSE,echo=TRUE>>=
depthContour(x, method = "Tukey", points = TRUE)
depthPersp(x, method = "Tukey")
@  
  
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{contours/t1}
    \includegraphics[width=0.5\textwidth]{contours/t2}
  \end{figure}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{Wykres głębia-versus-głebia}
\small
Wykres głębia-versus-głębia (ddPlot) porównuje wartości funkcji głębi punktu $x$, przy założeniu, że punkt generowany jest przez rozkład F, lub G (w praktycznych przypadkach F i G są zastępowane estymatorami z próby). Jeżeli $F = G$, wtedy ddPlot jest odcinkiem o końcach w $(0,0)$ i $(1,1)$. 

Interpretacja tego wykresu jest więc zbliżona do interpretacji wykresu kwantyl-kwantyl.
\vspace{60pt}
<<fig.width=4, fig.height=2>>=
set.seed(123)
cov = cbind(c(1,0.8),c(0.8,1))
x = mvrnorm(200, c(0,0), cov)
y = mvrnorm(200, c(0,0), cov)
p = ddPlot(x,y, method = "Tukey", exact = TRUE)
getPlot(p) + ggtitle("DDPlot - te same rozkłady") + theme_bw(10)
@

\end{frame}


\begin{frame}
  \frametitle{Wykres głębia-versus-głebia CD.}

<<fig.width=4.5, fig.height=3.1>>=
set.seed(123)

font_size = 7
cov = cbind(c(1,0.8),c(0.8,1))
x = mvrnorm(200, c(0,0), cov)
y = mvrnorm(200, c(0,0), cov)
p = ddPlot(x,y, method = "Tukey", exact = TRUE)
p = getPlot(p) + ggtitle("DDPlot - te same rozkłady") + theme_bw(font_size)

x = mvrnorm(200, c(0,0), cov)
y = mvrnorm(200, c(0,0), cbind(c(1,-0.8),c(-0.8,1)))
p2 = ddPlot(x,y, method = "Tukey", exact = TRUE)
p2 = getPlot(p2) + ggtitle("DDPlot - dwa rozkłady normalne\nRóżne macierze korelacji") + theme_bw(font_size)




x = cbind(rchallenge(200),rchallenge(200)*2)
y = cbind(rchallenge(200),rchallenge(200))


p3 = ddPlot(x,y, method = "Tukey", exact = TRUE)
p3 = getPlot(p3) + ggtitle("Niestandardowe rozkłady\nróżniące się rozproszeniem") + theme_bw(font_size)

x = cbind(rchallenge(200),rchallenge(200))
y = cbind(rchallenge(200),rchallenge(200))

p4 = ddPlot(x,y-2, method = "Tukey", exact = TRUE)
p4 = getPlot(p4) + ggtitle("Niestandardowe rozkłady\nróżniące się położeniem") + theme_bw(font_size)


p$layers[[1]]$geom_params$size = 1.5
p2$layers[[1]]$geom_params$size = 1.5
p3$layers[[1]]$geom_params$size = 1.5
p4$layers[[1]]$geom_params$size = 1.5

multiplot(p,p2,p3,p4, cols = 2)
@

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Obszar centralny}

\begin{definition}
Obszarem centralnym rzędu $\alpha$, $PC_F(\alpha)$ nazywamy zbiór punktów $x \in \RR$, takich, że $D(x, F) \geq \alpha$.
\end{definition}

<<>>=
set.seed(123)
N = 50
sigma = cbind(c(1,0.8),c(0.8,1))
x = mvrnorm(N, mu = c(0,0), sigma)
dp = (depth(x, method = "Tukey", exact = TRUE)>0.1)

par(mar = c(2,2,2,2))
plot(x,col = dp +1, pch = 19, xlab = "", ylab = "")

# rysowanie otoczki wypuklej
hull = geometry:::convhulln(x[dp,])
xx = x[dp, ]
xx = cbind(xx[hull,1], xx[hull,2])
points(xx, col = "blue", pch = 19)

# zaznaczenie obwodki na otoczce
points(x[dp,], col = "red", pch = 1)
@

\end{frame}



\begin{frame}
\frametitle{Krzywa skali}

Krzywa skali zdefiniowana jest jako:
\begin{equation}
SC(\alpha )=\left( \alpha ,vol({{D}_{\alpha }}({{{Z}}^{n}}) \right)\subset {{\mathbb{R}}^{2}},\hskip0.2mm   dla \hskip0.2mm \alpha \in [0,1],
\end{equation}
gdzie $vol({{D}_{\alpha }}({{{Z}}^{n}})$, jest to objętość otoczki wypukłej wznaczonej dla punktów znajdujących się w obszarze centralnym rzedu $\alpha$. Taka definicja pozwala na bardzo intuicyjną interpretację - im większe wartości na tej krzywej, tym zbiór jest bardziej rozproszony.


\end{frame}


\begin{frame}
[fragile]\frametitle{Krzywa skali - cd.}

<<echo=TRUE,fig.height=2.3>>=
set.seed(123)
sigma = cbind(c(1,0.8),c(0.8,1))
x = mvrnorm(180, mu = c(0,0), sigma)
y = mvrnorm(20, mu = c(1,-2), sigma*1.5)
z = rbind(x,y)
sc = scaleCurve(z,x, name = "z", name_y = "x")
# Wykresy wspolpracuja z ggplot2:
getPlot(sc) + scale_color_brewer(palette = "Set1")
@
\end{frame}

\begin{frame}
[fragile]\frametitle{Krzywa skali - cd. łączenie wykresów}
\small
Standardowo funckja scaleCurve może posłużyć do estymacji krzywej skali dla jednego, lub dwóch zbiorów danych. By zestawić ze sobą więcej krzywych należy skorzystać z operatora $\%+\%$, który pozwala na "dodawanie" do siebie wykresów.

<<echo=TRUE, fig.height=2.2>>=
sc_z = scaleCurve(z,name = "z")
sc_x = scaleCurve(x,name = "x")
sc_y = scaleCurve(y,name = "y")

sc = sc_x %+% sc_z %+% sc_y
getPlot(sc) + scale_color_brewer(palette = "Set1")
@
\end{frame}



\begin{frame}
[fragile]\frametitle{Krzywa skali. Łączenie wykresów, cd.}

<<>>=
data(inf.mort)
data(maesles.imm)
data(under5.mort)

inf.mort = cbind(name = rownames(inf.mort), inf.mort)
maesles.imm = cbind(name = rownames(maesles.imm), maesles.imm)
under5.mort = cbind(name = rownames(under5.mort), under5.mort)

inf.mort = melt(inf.mort)
maesles.imm = melt(maesles.imm)
maesles.imm[,3] = (100 - maesles.imm[,3])*10 # scale to #/1000
under5.mort = melt(under5.mort)

mrg = merge(maesles.imm, under5.mort, by = c("name","variable"))
mrg = merge(mrg, inf.mort, by = c("name","variable"))

all_data = na.omit(mrg)
colnames(all_data) = c("Country", "Year","maesles.imm", "under5.mort", "inf.mort")
@

<<warning=FALSE, echo=TRUE, fig.height=2>>=
scWrap = function(x) scaleCurve(x[,3:5], 
              name = as.character(x[1,2] %>% unlist))
sc_curves = all_data %>% group_by(Year) %>% 
  filter(as.numeric(Year)%%5 == 1) %>%
  do(scale_curves = scWrap(.))

scale_curves = sc_curves$scale_curves
scurves = Reduce("%+%", scale_curves)
getPlot(scurves) + xlim(c(0.6,1)) +
  ggtitle("") + guides(col = guide_legend(nrow = 7))
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
[fragile]\frametitle{Wielowymiarowa mediana}

\begin{definition}
  Punkt o najwyższej wartości funkcji głębi będziemy utożsamiać z wielowymiarową medianą.
\end{definition}

<<echo=TRUE>>=
data2010 = all_data %>% filter(Year == "2010") %>%
    select(maesles.imm, under5.mort, inf.mort) %>% 
  na.omit

depthMedian(data2010, method = "Tukey")
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Wielowymiarowy test Wilcoxona}

Dla próby ${{\mathbf{X}}^{m}}=\{{{\mathbf{X}}_{1}},...,{{\mathbf{X}}_{m}}\}$ , ${{\mathbf{Y}}^{n}}=\{{{\mathbf{Y}}_{1}},...,{{\mathbf{Y}}_{n}}\}$, i połączonej próby ${\mathbf{Z}}={{\mathbf{X}}^{n}}\cup {{\mathbf{Y}}^{m}}$ \textbf{statystyka Wilcoxona} zdefiniowana jest jako
\begin{equation}
S=\sum\limits_{i=1}^{m}{{{R}_{i}}},
\label{eq4}
\end{equation}
gdzie ${R}_{i}$ oznacza rangę i-tej obserwacji, $i=1,...,m$ w połączonej próbie $\mathbf{Z}$:

\begin{equation}
R({{\mathbf{x}}_{l}})=  \#\left\{ {{\mathbf{z}}_{j}}\in {{\mathbf{Z}}}:D({{\mathbf{z}}_{j}},{\mathbf{Z}})\le D({{\mathbf{x}}_{l}},{\mathbf{Z}}) \right\}, l=1,...,m.
\end{equation}

Rozkład $S$ jest symetryczny względem $E(S)=1/2m\text{(}m\text{+}n\text{+1)}$, a jego wariancja wynosi  ${{D}^{2}}(S)={1}/{12}\;mn(m+n+1).$ For theoretical properties statistic see \cite{Li:2004} and \cite{Zuo:2006}.\\


\end{frame}

\begin{frame}
[fragile]\frametitle{Wielowymiarowy test Wilcoxona - przykład}

\begin{columns}[T] % align columns
\begin{column}{.6\textwidth}
\vspace{-20pt}

<<echo=TRUE, results='hide'>>=
set.seed(123)
x  = mvrnorm(200, c(0,0), diag(2))
sigma = cbind(c(1,0.7), c(0.7,1))
y = mvrnorm(200, mu = c(0,0), sigma)

mWilcoxonTest(x,y, 
    alternative = "two.sided")
@

\end{column}%
\hfill%
  \begin{column}{.4\textwidth}
  
  \vspace{-20pt}
  \hspace{-11pt}
<<fig.width = 6.5, fig.height = 5>>=
par(mar = c(2,2,2,2))
plot(rbind(x,y), col = c(rep(1,200), rep(2,200)), pch = 19, xlab = "", ylab = "")
@
  
  \end{column}%
\end{columns}


<<>>=
mWilcoxonTest(x,y)
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Uogólniona głębia pasma}
\small

Uogólniona głębia pasma została zaproponowana w kontekście odpornej klasyfikacji obserwacji będących funkcjami.

Intuicyjnie określa średnią frakcję czasu jaką dana trajktoria znajduje się pomiędzy dwiema innymi trajektoriami z dostępnego zbioru.

Formalną definicję można znaleźć w \cite{DK2012}.

\end{frame}

\begin{frame}
[fragile]\frametitle{MBD - przykład}
\small
Poniżej zaprezentowano trajektorie bezrobocia rejestrowanego dla powiatów w Polsce od roku 2004 do 2013. Kolorami zaznaczono obszary w których znajduje się odpowiednio 100\%, 75\%, 50\% i 25\% najbardziej centralnych krzywych. Szerokość poszczególnych pasm (wykres po prawej) zmienia się w podobny sposób, co sugeruje, że pod względem zatrudnienia różnice pomiędzy powiatami na przestrzeni lat utrzymują się na zbliżonym poziomie.

<<>>=
data = read.csv2("dane_GUS.csv", dec =  ",", na.strings = "-", head = TRUE)
data = as.matrix(data[,3:12])
mode(data) = "numeric"
data = na.omit(data)
colors = brewer.pal(9,"YlOrRd") %>% tail(4)
@

<<fig.height = 2.5>>=
dp_mbd = depthMBD(data)

par(mfrow = c(1,2), mar = c(2,2,1,1))
plot(dp_mbd, band_lim = c(0,0.25,0.5,0.75), 
     col = colors, alpha = 0.8, add_lines = FALSE)
lines(data[which.max(dp_mbd),], lwd = 2)
plotBandWidth(dp_mbd, band_lim = c(0,0.25,0.5,0.75), colors = colors)
@
\end{frame}


\begin{frame}
[fragile]\frametitle{Szczegóły implementacyjne}
\scriptsize
Pakiet został napisany w dużej mierze z pomocą \textbf{Rcpp} i \textbf{RcppArmadillo}, co oznacza, że tak naprawdę spora część kodu jest napisana nie w \textbf{R}, tylko w \textbf{C++}.

Gdzie to możliwe wykorzystywane są obliczenia równoległe, zrealizowane na poziomie C++ przy pomocy \textbf{OpenMP} (jeżeli OpenMP jest niedostępne, DepthProc będzie ograniczony do jednego rdzenia). Domyślnie wykorzystywane są wszystkie dostępne rdzenie procesora, można jednak kontrolować to przy pomocy parametru \emph{threads}:

<<echo=TRUE>>=
x = matrix(rnorm(800000), ncol = 20)
system.time(d <- depth(x))
# jeden watek:
system.time(d <- depth(x, threads = 1))
@
\end{frame}

\begin{frame}
[allowframebreaks]
\bibliographystyle{plain}
\renewcommand\bibname{Literatura}
\bibliography{biblio}
\end{frame}

\end{document}
